{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we try to demonstrate the basic usage of the evolutionary parameter grid. Similar to the parameter grid in the \"Scikit-learn\" package, the basic usage between two packages is basically the same. However, in contrast to enumerate all possible combinations, this package uses the genetic algorithm to solve the unsolvable combinatorial optimization problem which may produce large grid search.\n",
    "\n",
    "Although there are a lot of evolutionary algorithm based parameter packages, most of them are only confined to the hyper-parameter search problem, and only few of them can be used as a general combinatorial optimization problem solver. Thus, this package provides a flexible combinatorial optimization problem solver, which can be easily used on various combinatorial optimization problems, such as hyper-parameter selection, feature selection, or even neural architecture search, as long as the parameter grid is well designed.\n",
    "\n",
    "In this tutorial, we use the hyper-parameter searching task as an example to demonstrate the usage of this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, we need to load the experimental dataset and to define the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T15:16:52.914731Z",
     "start_time": "2020-08-21T15:16:51.860320Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score, ParameterGrid, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from EvolutionaryParameterGrid import EAParameterGrid\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "param_grid = {\n",
    "    \"max_depth\": np.random.randint(1, (X.shape[1] * .85), 20),\n",
    "    \"max_features\": np.random.randint(1, X.shape[1], 20),\n",
    "    \"min_samples_leaf\": [2, 3, 4, 5, 6],\n",
    "    \"criterion\": [\"mse\", \"mae\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After loaded the experimental dataset, we can use the evolutionary parameter grid just as a traditional parameter grid. However, it should be note that, due to evolutionary algorithm need to intelligent tune it's exploration proposal based on the fitness score, i.e. , the cross validation score in our case. Thus, we need to manually set the fitness score after getting the cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T15:16:56.878873Z",
     "start_time": "2020-08-21T15:16:52.916730Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tstd     \tmin     \tmax     \n",
      "0  \t50    \t0.172936\t0.427611\t-2.23543\t0.521039\n",
      "1  \t50    \t0.397736\t0.11816 \t0.0286067\t0.522334\n",
      "2  \t50    \t0.476128\t0.101181\t0.156791 \t0.522334\n",
      "3  \t50    \t0.48994 \t0.0817068\t0.240743 \t0.522334\n",
      "4  \t50    \t0.487414\t0.0961236\t0.133501 \t0.522334\n",
      "5  \t50    \t0.489379\t0.123043 \t-0.290536\t0.522334\n",
      "6  \t50    \t0.498634\t0.0721583\t0.189493 \t0.522334\n",
      "7  \t50    \t0.495893\t0.090845 \t0.0234607\t0.522334\n",
      "8  \t50    \t0.484376\t0.0968043\t0.11605  \t0.522334\n",
      "9  \t50    \t0.507147\t0.0487307\t0.268768 \t0.522334\n",
      "10 \t50    \t0.490803\t0.115769 \t-0.104581\t0.522334\n",
      "11 \t50    \t0.500932\t0.136558 \t-0.450181\t0.522334\n",
      "12 \t50    \t0.480806\t0.142026 \t-0.364595\t0.522334\n",
      "13 \t50    \t0.51087 \t0.0488582\t0.240743 \t0.522334\n",
      "14 \t50    \t0.515311\t0.0377774\t0.268768 \t0.522334\n",
      "15 \t50    \t0.510662\t0.0568323\t0.13672  \t0.522334\n",
      "16 \t50    \t0.510165\t0.0621671\t0.116765 \t0.522334\n",
      "17 \t50    \t0.508568\t0.0813688\t-0.0523502\t0.522334\n",
      "18 \t50    \t0.506901\t0.060026 \t0.189493  \t0.522334\n",
      "19 \t50    \t0.509815\t0.0492805\t0.232679  \t0.522334\n",
      "20 \t50    \t0.512841\t0.0664536\t0.0476658 \t0.522334\n",
      "21 \t50    \t0.516034\t0.0309469\t0.353592  \t0.522334\n",
      "22 \t50    \t0.505948\t0.0718442\t0.133501  \t0.522334\n",
      "23 \t50    \t0.486756\t0.126613 \t-0.290536 \t0.522334\n",
      "24 \t50    \t0.522334\t0        \t0.522334  \t0.522334\n",
      "25 \t50    \t0.510143\t0.0448189\t0.269448  \t0.522334\n",
      "26 \t50    \t0.470685\t0.143728 \t-0.290536 \t0.522334\n",
      "27 \t50    \t0.504747\t0.068272 \t0.11605   \t0.522334\n",
      "28 \t50    \t0.492374\t0.0894497\t-0.0137869\t0.522334\n",
      "29 \t50    \t0.501441\t0.0564404\t0.232679  \t0.522334\n",
      "30 \t50    \t0.515938\t0.0318519\t0.316141  \t0.522334\n",
      "31 \t50    \t0.485571\t0.127384 \t-0.290536 \t0.522334\n",
      "32 \t50    \t0.516558\t0.0298026\t0.331152  \t0.522334\n",
      "33 \t50    \t0.496439\t0.0762486\t0.189493  \t0.522334\n",
      "34 \t50    \t0.50843 \t0.069097 \t0.116765  \t0.522334\n",
      "35 \t50    \t0.476923\t0.152117 \t-0.290536 \t0.522334\n",
      "36 \t50    \t0.50803 \t0.052493 \t0.189493  \t0.522334\n",
      "37 \t50    \t0.494488\t0.107024 \t-0.063558 \t0.522334\n",
      "38 \t50    \t0.482343\t0.118883 \t-0.15608  \t0.522334\n",
      "39 \t50    \t0.468215\t0.177246 \t-0.332658 \t0.522334\n",
      "40 \t50    \t0.507138\t0.0696257\t0.0790984 \t0.522334\n",
      "41 \t50    \t0.514662\t0.0466436\t0.189493  \t0.522334\n",
      "42 \t50    \t0.498117\t0.10209  \t-0.063558 \t0.522334\n",
      "43 \t50    \t0.499695\t0.0660493\t0.232679  \t0.522334\n",
      "44 \t50    \t0.511147\t0.050502 \t0.189493  \t0.522334\n",
      "45 \t50    \t0.488039\t0.100281 \t0.11605   \t0.522334\n",
      "46 \t50    \t0.492172\t0.131427 \t-0.290536 \t0.522334\n",
      "47 \t50    \t0.485379\t0.146192 \t-0.290536 \t0.522334\n",
      "48 \t50    \t0.444728\t0.297639 \t-1.45074  \t0.522334\n",
      "49 \t50    \t0.505974\t0.055931 \t0.303364  \t0.522334\n",
      "50 \t50    \t0.491153\t0.0881546\t0.11605   \t0.522334\n"
     ]
    }
   ],
   "source": [
    "grid = EAParameterGrid()\n",
    "for param in grid.grid(param_grid):\n",
    "    tree = DecisionTreeRegressor(**param,random_state=0)\n",
    "    score = cross_val_score(tree, X, y, cv=5)\n",
    "    grid.set_fitness(np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It should be noted that, although we set a huge population size and a huge generation number, that does not mean that we really need to evaluate such many proposals. Because we use a memory mechanism in our package, we only need to evaluate a small fraction of those proposals, because most of them are repetitive proposals. Therefore, we use the following command to examine the real evaluation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T15:16:56.889868Z",
     "start_time": "2020-08-21T15:16:56.879873Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.history_dict.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Well, it seems that we only use 200 times to try different parameter combinations. Is that really useful? We can compare it with the well-known random search method under the same evaluation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T15:17:01.309469Z",
     "start_time": "2020-08-21T15:16:56.891865Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5098659816094302"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RandomizedSearchCV(DecisionTreeRegressor(random_state=0),\n",
    "                        param_grid,\n",
    "                        n_iter=200,\n",
    "                        cv=5,\n",
    "                        verbose=1)\n",
    "cv.fit(X, y)\n",
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the result, we find that the evolutionary based method is more efficient compared with the random search method. This is not out of our surprise because it has been proved in many applications. Thus, we highly recommend using evolutionary based search as an enhancement method when there is no available algorithm other than random search, because it often can achieve an unexpected high performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
